# PyTorch Study Notes üß†üî•

This repository is a structured collection of notes, code snippets, and working models from my self-guided PyTorch studies. Each file contains practical experiments, explanations, and reflections to help deepen my understanding of core deep learning concepts.

## üóÇÔ∏è Contents

| File        | Topic Covered |
|-------------|----------------|
| `pt1.py`    | Tensor creation, operations, and NumPy compatibility |
| `pt2.py`    | Gradients, autograd mechanics, and backward propagation |
| `pt3.py`    | Manual backpropagation with linear regression |
| `pt4.py`    | Optimization loop using PyTorch's built-in tools |
| `pt5.py`    | Model training with `nn.Linear`, loss, and optimizer |
| `pt6.py`    | Custom model class and training with real regression data |
| `pt7.py`    | Logistic regression for binary classification |
| `pt8.py`    | Dataset, `DataLoader`, and batch training |
| `pt9.py`    | Data transformations using custom and composed transforms |
| `pt10.py`   | Classification with dropout, batch normalization, and softmax/logits |
| `pt11.py`   | Overview of common activation functions like ReLU, Sigmoid, Tanh |
| `whatever.py` | Refined classification pipeline using Adam optimizer, dropout, batch normalization, and test evaluation |

## üîß Environment

- Python 3.8+
- PyTorch
- NumPy, Pandas
- scikit-learn
- Matplotlib (for visualizations)

Install with:
```bash
pip install torch torchvision numpy pandas scikit-learn matplotlib
